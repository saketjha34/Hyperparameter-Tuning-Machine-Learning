{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  chest pain type  resting bp s  cholesterol  \\\n",
       "0      40    1                2           140          289   \n",
       "1      49    0                3           160          180   \n",
       "2      37    1                2           130          283   \n",
       "3      48    0                4           138          214   \n",
       "4      54    1                3           150          195   \n",
       "...   ...  ...              ...           ...          ...   \n",
       "1185   45    1                1           110          264   \n",
       "1186   68    1                4           144          193   \n",
       "1187   57    1                4           130          131   \n",
       "1188   57    0                2           130          236   \n",
       "1189   38    1                3           138          175   \n",
       "\n",
       "      fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "0                       0            0             172                0   \n",
       "1                       0            0             156                0   \n",
       "2                       0            1              98                0   \n",
       "3                       0            0             108                1   \n",
       "4                       0            0             122                0   \n",
       "...                   ...          ...             ...              ...   \n",
       "1185                    0            0             132                0   \n",
       "1186                    1            0             141                0   \n",
       "1187                    0            0             115                1   \n",
       "1188                    0            2             174                0   \n",
       "1189                    0            0             173                0   \n",
       "\n",
       "      oldpeak  ST slope  target  \n",
       "0         0.0         1       0  \n",
       "1         1.0         2       1  \n",
       "2         0.0         1       0  \n",
       "3         1.5         2       1  \n",
       "4         0.0         1       0  \n",
       "...       ...       ...     ...  \n",
       "1185      1.2         2       1  \n",
       "1186      3.4         2       1  \n",
       "1187      1.2         2       1  \n",
       "1188      0.0         2       1  \n",
       "1189      0.0         1       0  \n",
       "\n",
       "[1190 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('csv\\\\heart.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',\n",
       "       'fasting blood sugar', 'resting ecg', 'max heart rate',\n",
       "       'exercise angina', 'oldpeak', 'ST slope', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                    0\n",
       "sex                    0\n",
       "chest pain type        0\n",
       "resting bp s           0\n",
       "cholesterol            0\n",
       "fasting blood sugar    0\n",
       "resting ecg            0\n",
       "max heart rate         0\n",
       "exercise angina        0\n",
       "oldpeak                0\n",
       "ST slope               0\n",
       "target                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.720168</td>\n",
       "      <td>0.763866</td>\n",
       "      <td>3.232773</td>\n",
       "      <td>132.153782</td>\n",
       "      <td>210.363866</td>\n",
       "      <td>0.213445</td>\n",
       "      <td>0.698319</td>\n",
       "      <td>139.732773</td>\n",
       "      <td>0.387395</td>\n",
       "      <td>0.922773</td>\n",
       "      <td>1.624370</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.358203</td>\n",
       "      <td>0.424884</td>\n",
       "      <td>0.935480</td>\n",
       "      <td>18.368823</td>\n",
       "      <td>101.420489</td>\n",
       "      <td>0.409912</td>\n",
       "      <td>0.870359</td>\n",
       "      <td>25.517636</td>\n",
       "      <td>0.487360</td>\n",
       "      <td>1.086337</td>\n",
       "      <td>0.610459</td>\n",
       "      <td>0.499393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>269.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex  chest pain type  resting bp s  cholesterol  \\\n",
       "count  1190.000000  1190.000000      1190.000000   1190.000000  1190.000000   \n",
       "mean     53.720168     0.763866         3.232773    132.153782   210.363866   \n",
       "std       9.358203     0.424884         0.935480     18.368823   101.420489   \n",
       "min      28.000000     0.000000         1.000000      0.000000     0.000000   \n",
       "25%      47.000000     1.000000         3.000000    120.000000   188.000000   \n",
       "50%      54.000000     1.000000         4.000000    130.000000   229.000000   \n",
       "75%      60.000000     1.000000         4.000000    140.000000   269.750000   \n",
       "max      77.000000     1.000000         4.000000    200.000000   603.000000   \n",
       "\n",
       "       fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "count          1190.000000  1190.000000     1190.000000      1190.000000   \n",
       "mean              0.213445     0.698319      139.732773         0.387395   \n",
       "std               0.409912     0.870359       25.517636         0.487360   \n",
       "min               0.000000     0.000000       60.000000         0.000000   \n",
       "25%               0.000000     0.000000      121.000000         0.000000   \n",
       "50%               0.000000     0.000000      140.500000         0.000000   \n",
       "75%               0.000000     2.000000      160.000000         1.000000   \n",
       "max               1.000000     2.000000      202.000000         1.000000   \n",
       "\n",
       "           oldpeak     ST slope       target  \n",
       "count  1190.000000  1190.000000  1190.000000  \n",
       "mean      0.922773     1.624370     0.528571  \n",
       "std       1.086337     0.610459     0.499393  \n",
       "min      -2.600000     0.000000     0.000000  \n",
       "25%       0.000000     1.000000     0.000000  \n",
       "50%       0.600000     2.000000     1.000000  \n",
       "75%       1.600000     2.000000     1.000000  \n",
       "max       6.200000     3.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',\n",
    "       'fasting blood sugar', 'resting ecg', 'max heart rate',\n",
    "       'exercise angina', 'oldpeak', 'ST slope',]\n",
    "target_col = 'target'\n",
    "numeric_cols = ['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',\n",
    "       'fasting blood sugar', 'resting ecg', 'max heart rate',\n",
    "       'exercise angina', 'oldpeak', 'ST slope',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = df[input_cols].copy()\n",
    "train_targets = df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  chest pain type  resting bp s  cholesterol  \\\n",
       "0      40    1                2           140          289   \n",
       "1      49    0                3           160          180   \n",
       "2      37    1                2           130          283   \n",
       "3      48    0                4           138          214   \n",
       "4      54    1                3           150          195   \n",
       "...   ...  ...              ...           ...          ...   \n",
       "1185   45    1                1           110          264   \n",
       "1186   68    1                4           144          193   \n",
       "1187   57    1                4           130          131   \n",
       "1188   57    0                2           130          236   \n",
       "1189   38    1                3           138          175   \n",
       "\n",
       "      fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "0                       0            0             172                0   \n",
       "1                       0            0             156                0   \n",
       "2                       0            1              98                0   \n",
       "3                       0            0             108                1   \n",
       "4                       0            0             122                0   \n",
       "...                   ...          ...             ...              ...   \n",
       "1185                    0            0             132                0   \n",
       "1186                    1            0             141                0   \n",
       "1187                    0            0             115                1   \n",
       "1188                    0            2             174                0   \n",
       "1189                    0            0             173                0   \n",
       "\n",
       "      oldpeak  ST slope  \n",
       "0         0.0         1  \n",
       "1         1.0         2  \n",
       "2         0.0         1  \n",
       "3         1.5         2  \n",
       "4         0.0         1  \n",
       "...       ...       ...  \n",
       "1185      1.2         2  \n",
       "1186      3.4         2  \n",
       "1187      1.2         2  \n",
       "1188      0.0         2  \n",
       "1189      0.0         1  \n",
       "\n",
       "[1190 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "1185    1\n",
       "1186    1\n",
       "1187    1\n",
       "1188    1\n",
       "1189    0\n",
       "Name: target, Length: 1190, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.479270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.469320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.354892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.323383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>0.346939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.437811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>0.816327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.320066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.217247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.391376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>0.204082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.290216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sex  chest pain type  resting bp s  cholesterol  \\\n",
       "0     0.244898  1.0         0.333333          0.70     0.479270   \n",
       "1     0.428571  0.0         0.666667          0.80     0.298507   \n",
       "2     0.183673  1.0         0.333333          0.65     0.469320   \n",
       "3     0.408163  0.0         1.000000          0.69     0.354892   \n",
       "4     0.530612  1.0         0.666667          0.75     0.323383   \n",
       "...        ...  ...              ...           ...          ...   \n",
       "1185  0.346939  1.0         0.000000          0.55     0.437811   \n",
       "1186  0.816327  1.0         1.000000          0.72     0.320066   \n",
       "1187  0.591837  1.0         1.000000          0.65     0.217247   \n",
       "1188  0.591837  0.0         0.333333          0.65     0.391376   \n",
       "1189  0.204082  1.0         0.666667          0.69     0.290216   \n",
       "\n",
       "      fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "0                     0.0          0.0        0.788732              0.0   \n",
       "1                     0.0          0.0        0.676056              0.0   \n",
       "2                     0.0          0.5        0.267606              0.0   \n",
       "3                     0.0          0.0        0.338028              1.0   \n",
       "4                     0.0          0.0        0.436620              0.0   \n",
       "...                   ...          ...             ...              ...   \n",
       "1185                  0.0          0.0        0.507042              0.0   \n",
       "1186                  1.0          0.0        0.570423              0.0   \n",
       "1187                  0.0          0.0        0.387324              1.0   \n",
       "1188                  0.0          1.0        0.802817              0.0   \n",
       "1189                  0.0          0.0        0.795775              0.0   \n",
       "\n",
       "       oldpeak  ST slope  \n",
       "0     0.295455  0.333333  \n",
       "1     0.409091  0.666667  \n",
       "2     0.295455  0.333333  \n",
       "3     0.465909  0.666667  \n",
       "4     0.295455  0.333333  \n",
       "...        ...       ...  \n",
       "1185  0.431818  0.666667  \n",
       "1186  0.681818  0.666667  \n",
       "1187  0.431818  0.666667  \n",
       "1188  0.295455  0.666667  \n",
       "1189  0.295455  0.333333  \n",
       "\n",
       "[1190 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_inputs[numeric_cols])\n",
    "\n",
    "train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])\n",
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, train_targets, val_targets = train_test_split(train_inputs, train_targets, test_size=0.35  ,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.469388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.311774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.755102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.391376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.316901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.408163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.456053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.551020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0.612245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.551020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.434494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.489221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.718310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sex  chest pain type  resting bp s  cholesterol  \\\n",
       "29    0.469388  1.0         0.333333         0.625     0.311774   \n",
       "423   0.755102  1.0         1.000000         0.750     0.391376   \n",
       "165   0.489796  0.0         0.333333         0.700     0.373134   \n",
       "248   0.408163  1.0         1.000000         0.610     0.456053   \n",
       "307   0.551020  1.0         1.000000         0.575     0.000000   \n",
       "...        ...  ...              ...           ...          ...   \n",
       "1044  0.612245  1.0         1.000000         0.625     0.497512   \n",
       "1095  0.551020  1.0         0.333333         0.650     0.434494   \n",
       "1130  0.673469  1.0         0.000000         0.670     0.388060   \n",
       "860   0.693878  0.0         1.000000         0.700     0.444444   \n",
       "1126  0.285714  1.0         0.333333         0.600     0.489221   \n",
       "\n",
       "      fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "29                    0.0          0.0        0.598592              0.0   \n",
       "423                   1.0          0.5        0.316901              1.0   \n",
       "165                   0.0          0.0        0.563380              0.0   \n",
       "248                   1.0          0.5        0.633803              1.0   \n",
       "307                   1.0          0.0        0.669014              0.0   \n",
       "...                   ...          ...             ...              ...   \n",
       "1044                  0.0          1.0        0.781690              0.0   \n",
       "1095                  0.0          0.0        0.669014              0.0   \n",
       "1130                  0.0          0.0        0.598592              0.0   \n",
       "860                   0.0          1.0        0.704225              0.0   \n",
       "1126                  0.0          0.0        0.718310              0.0   \n",
       "\n",
       "       oldpeak  ST slope  \n",
       "29    0.295455  0.333333  \n",
       "423   0.295455  0.666667  \n",
       "165   0.295455  0.333333  \n",
       "248   0.522727  1.000000  \n",
       "307   0.306818  0.666667  \n",
       "...        ...       ...  \n",
       "1044  0.295455  0.333333  \n",
       "1095  0.295455  0.333333  \n",
       "1130  0.590909  0.666667  \n",
       "860   0.704545  1.000000  \n",
       "1126  0.295455  0.333333  \n",
       "\n",
       "[773 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29      0\n",
       "423     1\n",
       "165     0\n",
       "248     1\n",
       "307     1\n",
       "       ..\n",
       "1044    1\n",
       "1095    0\n",
       "1130    1\n",
       "860     1\n",
       "1126    0\n",
       "Name: target, Length: 773, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>resting bp s</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>resting ecg</th>\n",
       "      <th>max heart rate</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ST slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.598592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.530612</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.393035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.465909</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.530680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.427861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.683099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.551020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.459370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.509121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.346939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.431177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0.489796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.386401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>417 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sex  chest pain type  resting bp s  cholesterol  \\\n",
       "390   0.673469  1.0         1.000000         0.800     0.000000   \n",
       "247   0.530612  1.0         0.666667         0.600     0.393035   \n",
       "260   0.551020  0.0         0.333333         0.610     0.530680   \n",
       "155   0.571429  1.0         1.000000         0.775     0.567164   \n",
       "984   0.653061  0.0         1.000000         0.750     0.427861   \n",
       "...        ...  ...              ...           ...          ...   \n",
       "682   0.591837  1.0         1.000000         0.750     0.457711   \n",
       "80    0.551020  1.0         0.666667         0.550     0.459370   \n",
       "997   0.673469  0.0         1.000000         0.725     0.509121   \n",
       "987   0.346939  1.0         1.000000         0.575     0.431177   \n",
       "1063  0.489796  1.0         1.000000         0.540     0.386401   \n",
       "\n",
       "      fasting blood sugar  resting ecg  max heart rate  exercise angina  \\\n",
       "390                   1.0          0.5        0.598592              0.0   \n",
       "247                   0.0          0.0        0.633803              1.0   \n",
       "260                   0.0          0.0        0.669014              0.0   \n",
       "155                   1.0          0.0        0.633803              1.0   \n",
       "984                   0.0          1.0        0.683099              0.0   \n",
       "...                   ...          ...             ...              ...   \n",
       "682                   0.0          1.0        0.366197              1.0   \n",
       "80                    0.0          0.0        0.704225              0.0   \n",
       "997                   0.0          1.0        0.605634              1.0   \n",
       "987                   0.0          1.0        0.880282              0.0   \n",
       "1063                  1.0          0.0        0.612676              0.0   \n",
       "\n",
       "       oldpeak  ST slope  \n",
       "390   0.409091  0.666667  \n",
       "247   0.465909  0.666667  \n",
       "260   0.295455  0.333333  \n",
       "155   0.636364  0.666667  \n",
       "984   0.590909  0.666667  \n",
       "...        ...       ...  \n",
       "682   0.363636  0.666667  \n",
       "80    0.295455  0.333333  \n",
       "997   0.409091  0.666667  \n",
       "987   0.295455  0.333333  \n",
       "1063  0.306818  0.333333  \n",
       "\n",
       "[417 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390     1\n",
       "247     1\n",
       "260     0\n",
       "155     1\n",
       "984     1\n",
       "       ..\n",
       "682     1\n",
       "80      0\n",
       "997     1\n",
       "987     0\n",
       "1063    0\n",
       "Name: target, Length: 417, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489208633093526"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,train_targets)\n",
    "lr.score(X_val,val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537170263788969"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,train_targets)\n",
    "dt.score(X_val,val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9232613908872902"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,train_targets)\n",
    "rf.score(X_val,val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_val, train_targets, val_targets):\n",
    "    model.fit(X_train, train_targets)\n",
    "    return model.score(X_val, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRIDSEARCHCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "450 fits failed out of a total of 1800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "450 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.8031968  0.80579421 0.8044955  0.8044955  0.80191475        nan\n",
      "        nan        nan        nan        nan 0.86533467 0.86143856\n",
      " 0.86012321 0.86013986 0.86013986 0.87307692 0.87052947 0.86921412\n",
      " 0.87049617 0.86660007 0.8031968  0.80579421 0.8044955  0.8044955\n",
      " 0.80191475        nan        nan        nan        nan        nan\n",
      " 0.89518815 0.89388944 0.89388944 0.89130869 0.89388944 0.88869464\n",
      " 0.89129204 0.89129204 0.89130869 0.88869464 0.8031968  0.80579421\n",
      " 0.8044955  0.8044955  0.80191475        nan        nan        nan\n",
      "        nan        nan 0.90164835 0.9042291  0.90684316 0.90554446\n",
      " 0.90424575 0.9002997  0.90161505 0.900333   0.90161505 0.90291375\n",
      " 0.8044955  0.80709291 0.80579421 0.80579421 0.80321345        nan\n",
      "        nan        nan        nan        nan 0.86918082 0.86661672\n",
      " 0.86789877 0.86660007 0.86530137 0.86403596 0.86531802 0.86272061\n",
      " 0.86145521 0.86531802 0.8044955  0.80709291 0.80579421 0.80579421\n",
      " 0.80321345        nan        nan        nan        nan        nan\n",
      " 0.8951715  0.89515485 0.89382284 0.89383949 0.89382284 0.89259074\n",
      " 0.89387279 0.89125874 0.88994339 0.88737929 0.8044955  0.80709291\n",
      " 0.80579421 0.80579421 0.80321345        nan        nan        nan\n",
      "        nan        nan 0.89515485 0.8964369  0.89385614 0.89515485\n",
      " 0.89775225 0.90034965 0.8977689  0.8951715  0.90034965 0.9016317\n",
      " 0.8044955  0.80709291 0.80579421 0.80579421 0.80321345        nan\n",
      "        nan        nan        nan        nan 0.86918082 0.86661672\n",
      " 0.86789877 0.86660007 0.86530137 0.86403596 0.86531802 0.86272061\n",
      " 0.86145521 0.86531802 0.8044955  0.80709291 0.80579421 0.80579421\n",
      " 0.80321345        nan        nan        nan        nan        nan\n",
      " 0.8951715  0.89515485 0.89382284 0.89383949 0.89382284 0.89259074\n",
      " 0.89387279 0.89125874 0.88994339 0.88737929 0.8044955  0.80709291\n",
      " 0.80579421 0.80579421 0.80321345        nan        nan        nan\n",
      "        nan        nan 0.89515485 0.8964369  0.89385614 0.89515485\n",
      " 0.89775225 0.90034965 0.8977689  0.8951715  0.90034965 0.9016317 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.25707674e-02, 1.04559851e-01, 1.10259604e-01, 1.17694092e-01,\n",
       "        1.27082705e-01, 7.87258148e-04, 7.13014603e-04, 6.60514832e-04,\n",
       "        3.93605232e-04, 5.94449043e-04, 1.39114594e-01, 1.86986518e-01,\n",
       "        1.95412779e-01, 2.08096671e-01, 2.27774882e-01, 1.41571736e-01,\n",
       "        1.69056845e-01, 1.85425568e-01, 2.01980591e-01, 2.72085643e-01,\n",
       "        1.04406500e-01, 1.70114923e-01, 2.06513405e-01, 2.01825333e-01,\n",
       "        2.55393910e-01, 1.55017376e-03, 9.17696953e-04, 1.23829842e-03,\n",
       "        1.10046864e-03, 1.06956959e-03, 2.48175740e-01, 2.86167383e-01,\n",
       "        3.54742146e-01, 4.01557803e-01, 3.71399999e-01, 2.23014903e-01,\n",
       "        3.09640026e-01, 3.21385384e-01, 3.18135810e-01, 3.35159636e-01,\n",
       "        1.37195444e-01, 1.68990755e-01, 1.73952484e-01, 1.85996318e-01,\n",
       "        1.43812990e-01, 1.04496479e-03, 9.70363617e-04, 3.06367874e-04,\n",
       "        1.01923943e-04, 6.40130043e-04, 1.86349988e-01, 2.25553679e-01,\n",
       "        2.35478377e-01, 2.52925968e-01, 2.72641754e-01, 1.78681493e-01,\n",
       "        2.10355973e-01, 2.28687596e-01, 2.49440789e-01, 2.67121625e-01,\n",
       "        9.01193142e-02, 1.14270353e-01, 1.24407053e-01, 1.26463127e-01,\n",
       "        1.40293956e-01, 4.00137901e-04, 2.50387192e-04, 5.62334061e-04,\n",
       "        0.00000000e+00, 3.01909447e-04, 1.57099771e-01, 1.86460328e-01,\n",
       "        2.03149128e-01, 2.17862678e-01, 2.31762338e-01, 1.53646970e-01,\n",
       "        1.99638963e-01, 1.99857545e-01, 2.23711920e-01, 2.29047322e-01,\n",
       "        9.27111387e-02, 1.13262987e-01, 1.18266726e-01, 1.34339595e-01,\n",
       "        1.57588100e-01, 4.23002243e-04, 7.04050064e-04, 9.87553596e-04,\n",
       "        7.61485100e-04, 5.98239899e-04, 1.86990547e-01, 2.04143071e-01,\n",
       "        2.23633027e-01, 2.42259741e-01, 2.69692254e-01, 1.75788474e-01,\n",
       "        2.17035341e-01, 2.22936106e-01, 2.37595868e-01, 2.59422040e-01,\n",
       "        9.53524590e-02, 1.13596511e-01, 1.18005991e-01, 1.33864284e-01,\n",
       "        1.37055707e-01, 6.57272339e-04, 2.24399567e-04, 5.93042374e-04,\n",
       "        3.71146202e-04, 8.49056244e-04, 1.84752703e-01, 2.19618654e-01,\n",
       "        2.42601919e-01, 2.57859540e-01, 2.73377085e-01, 1.80334282e-01,\n",
       "        2.18796110e-01, 2.35386825e-01, 2.54505157e-01, 2.75112104e-01,\n",
       "        9.75050926e-02, 1.11345100e-01, 1.24351144e-01, 1.28394985e-01,\n",
       "        1.38426757e-01, 8.01038742e-04, 2.00152397e-04, 4.46701050e-04,\n",
       "        9.00316238e-04, 4.96029854e-04, 1.58298540e-01, 1.85674763e-01,\n",
       "        1.96891880e-01, 2.22363591e-01, 2.35416460e-01, 1.54915285e-01,\n",
       "        1.82942080e-01, 2.01635718e-01, 2.29800224e-01, 2.34213734e-01,\n",
       "        9.68735218e-02, 1.12167883e-01, 1.17003536e-01, 1.31642962e-01,\n",
       "        1.39854002e-01, 6.99400902e-04, 9.76204872e-04, 5.08522987e-04,\n",
       "        5.29408455e-04, 6.00075722e-04, 1.75234628e-01, 2.08802748e-01,\n",
       "        2.22063661e-01, 2.36973262e-01, 2.60126948e-01, 1.76252604e-01,\n",
       "        2.09216619e-01, 2.23944497e-01, 2.37323952e-01, 2.62774324e-01,\n",
       "        1.01680279e-01, 1.18287563e-01, 1.28600264e-01, 1.38194227e-01,\n",
       "        1.42691422e-01, 3.23510170e-04, 6.09827042e-04, 6.60443306e-04,\n",
       "        7.51042366e-04, 8.31389427e-04, 1.97807670e-01, 2.51080990e-01,\n",
       "        2.58923268e-01, 2.82978654e-01, 2.82263947e-01, 2.01156211e-01,\n",
       "        2.34747338e-01, 2.63504887e-01, 2.83205414e-01, 2.94935632e-01]),\n",
       " 'std_fit_time': array([0.00755863, 0.00676302, 0.00846823, 0.00380044, 0.00698257,\n",
       "        0.00039603, 0.00046735, 0.00057242, 0.0004828 , 0.00048655,\n",
       "        0.00394792, 0.02235772, 0.01297645, 0.0148237 , 0.01484144,\n",
       "        0.00628313, 0.00724169, 0.00746497, 0.0063611 , 0.03716472,\n",
       "        0.00394051, 0.05997378, 0.022935  , 0.02216987, 0.02894378,\n",
       "        0.00064933, 0.00039182, 0.00052867, 0.00049418, 0.00069215,\n",
       "        0.02224312, 0.01469744, 0.03980195, 0.0329921 , 0.03557234,\n",
       "        0.02443237, 0.02151851, 0.04082692, 0.01712571, 0.02526807,\n",
       "        0.0235594 , 0.01239718, 0.02573544, 0.02955115, 0.00500939,\n",
       "        0.00046339, 0.00012886, 0.00046817, 0.00030577, 0.00070956,\n",
       "        0.00493764, 0.01755776, 0.01869224, 0.01336931, 0.02212375,\n",
       "        0.01071548, 0.01071247, 0.01157333, 0.01061452, 0.01371822,\n",
       "        0.00352653, 0.00335226, 0.0052192 , 0.00555984, 0.00450006,\n",
       "        0.00049007, 0.00040322, 0.0006132 , 0.        , 0.00046121,\n",
       "        0.0093801 , 0.00666366, 0.00736381, 0.01205403, 0.00559604,\n",
       "        0.00867559, 0.01616662, 0.01128348, 0.01153739, 0.01110203,\n",
       "        0.00575499, 0.00490577, 0.00575237, 0.00268676, 0.00742406,\n",
       "        0.00052104, 0.00046102, 0.00035115, 0.00053604, 0.00048847,\n",
       "        0.00841928, 0.00801191, 0.01327105, 0.01242289, 0.01220662,\n",
       "        0.014928  , 0.02014095, 0.01174898, 0.01542281, 0.01242035,\n",
       "        0.00551016, 0.00559381, 0.00594391, 0.00665085, 0.00758172,\n",
       "        0.00044544, 0.00036246, 0.00048441, 0.0004692 , 0.0006222 ,\n",
       "        0.01170191, 0.0126678 , 0.0319732 , 0.01326126, 0.01226778,\n",
       "        0.00849135, 0.01105051, 0.00947551, 0.00929454, 0.00968966,\n",
       "        0.00553786, 0.00695466, 0.00380231, 0.00606086, 0.00718188,\n",
       "        0.00040109, 0.0004003 , 0.00052538, 0.00030012, 0.00049845,\n",
       "        0.00525562, 0.01017642, 0.00764246, 0.01372492, 0.01436196,\n",
       "        0.01007749, 0.00804062, 0.01128627, 0.00980289, 0.0134729 ,\n",
       "        0.00692676, 0.00592824, 0.004096  , 0.00559773, 0.00415707,\n",
       "        0.00045877, 0.00012967, 0.00050959, 0.00048773, 0.00049011,\n",
       "        0.0148555 , 0.01392161, 0.00882279, 0.01138941, 0.0097229 ,\n",
       "        0.0084029 , 0.01221053, 0.01056308, 0.01103085, 0.01924259,\n",
       "        0.00664268, 0.00906033, 0.00884248, 0.00475753, 0.0068521 ,\n",
       "        0.00049807, 0.00049867, 0.000454  , 0.00067133, 0.00076254,\n",
       "        0.01445739, 0.02669088, 0.00906234, 0.01752294, 0.00961663,\n",
       "        0.01496599, 0.01490453, 0.02246581, 0.01880222, 0.02508272]),\n",
       " 'mean_score_time': array([0.00553715, 0.00694156, 0.00695875, 0.00764844, 0.00830772,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00638452, 0.00885582, 0.00860174, 0.00851068, 0.00953882,\n",
       "        0.00651658, 0.00752752, 0.00799241, 0.00861218, 0.01156218,\n",
       "        0.00675585, 0.01325746, 0.01785989, 0.01673331, 0.0178225 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01220124, 0.01300902, 0.01899335, 0.01900272, 0.01781473,\n",
       "        0.01200442, 0.01430969, 0.01402938, 0.01379917, 0.01525426,\n",
       "        0.01180832, 0.01128604, 0.01363628, 0.01410129, 0.00890715,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00704818, 0.00883689, 0.00904016, 0.00921996, 0.00969672,\n",
       "        0.007126  , 0.00793431, 0.00877612, 0.0093869 , 0.00979645,\n",
       "        0.00611753, 0.00739543, 0.00776191, 0.00850332, 0.00848484,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00712717, 0.0077523 , 0.00873244, 0.00895295, 0.00897155,\n",
       "        0.00666308, 0.00854979, 0.00843616, 0.00918436, 0.0094027 ,\n",
       "        0.00623424, 0.00757146, 0.0076494 , 0.00890722, 0.01024952,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00762317, 0.00745738, 0.00905237, 0.00913405, 0.0101037 ,\n",
       "        0.00712109, 0.00834239, 0.00815508, 0.00943167, 0.01016257,\n",
       "        0.00673189, 0.00759099, 0.00736957, 0.00849838, 0.00904126,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00722072, 0.00782108, 0.00859854, 0.00930352, 0.00960324,\n",
       "        0.00722754, 0.00809877, 0.00866885, 0.00889342, 0.01034625,\n",
       "        0.00681744, 0.00701039, 0.00756941, 0.00776944, 0.00914354,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00714355, 0.00782056, 0.00801227, 0.00934937, 0.00927281,\n",
       "        0.00719345, 0.00820837, 0.00840814, 0.00958748, 0.00953352,\n",
       "        0.00653217, 0.00722435, 0.00756137, 0.00860381, 0.00876098,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00687103, 0.00812032, 0.00851154, 0.00918148, 0.00955086,\n",
       "        0.0070518 , 0.00791116, 0.00860124, 0.00845284, 0.00998158,\n",
       "        0.00681853, 0.00772486, 0.00799654, 0.00899045, 0.0090894 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00717809, 0.00952625, 0.00954227, 0.01061823, 0.00989158,\n",
       "        0.00746021, 0.00839822, 0.00983856, 0.0098877 , 0.01053464]),\n",
       " 'std_score_time': array([0.00055126, 0.00088957, 0.00047321, 0.00079311, 0.00040153,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00080309, 0.00249844, 0.00103714, 0.00071339, 0.00049561,\n",
       "        0.00083047, 0.00060921, 0.00086981, 0.00072643, 0.00188996,\n",
       "        0.00048832, 0.00513915, 0.00209458, 0.00366256, 0.00329693,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00227067, 0.00292014, 0.00293723, 0.00190608, 0.00239862,\n",
       "        0.00274278, 0.00530355, 0.00256078, 0.00274291, 0.00318286,\n",
       "        0.00314141, 0.00325549, 0.00368256, 0.00615296, 0.00101579,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00065793, 0.00085714, 0.00082833, 0.00055326, 0.00089645,\n",
       "        0.00064525, 0.00078672, 0.00072166, 0.00041208, 0.00107512,\n",
       "        0.00072271, 0.0003496 , 0.00088833, 0.00100081, 0.00090494,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00068424, 0.00068513, 0.00060493, 0.00072449, 0.00086654,\n",
       "        0.00066841, 0.00089249, 0.00080153, 0.00083825, 0.00073389,\n",
       "        0.0008823 , 0.0009397 , 0.00098776, 0.00141905, 0.00061986,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00075935, 0.00050397, 0.00077744, 0.00126437, 0.00061375,\n",
       "        0.00102133, 0.00097285, 0.00105271, 0.00083932, 0.00087814,\n",
       "        0.00084607, 0.00105268, 0.00073954, 0.00104521, 0.00077868,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00080683, 0.00051024, 0.00117932, 0.00085438, 0.00100615,\n",
       "        0.00069891, 0.00098945, 0.00056009, 0.00067983, 0.00095144,\n",
       "        0.00086619, 0.00078594, 0.00054075, 0.00069572, 0.00114207,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00065014, 0.00091743, 0.00067641, 0.0020056 , 0.00090235,\n",
       "        0.00068003, 0.00099328, 0.00058166, 0.00098183, 0.00111649,\n",
       "        0.00065851, 0.00087692, 0.00073207, 0.00060712, 0.00130649,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0010118 , 0.00046358, 0.00076888, 0.00085711, 0.00069938,\n",
       "        0.00087282, 0.00087813, 0.00044425, 0.00059732, 0.00103196,\n",
       "        0.00098764, 0.0009585 , 0.00072141, 0.00112992, 0.00129276,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00078303, 0.00320616, 0.00069865, 0.00161511, 0.00102133,\n",
       "        0.0008262 , 0.00085525, 0.00177484, 0.00106868, 0.00114383]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss', 'log_loss',\n",
       "                    'log_loss', 'log_loss', 'log_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "                    3, 3, 3, 3, 3, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1,\n",
       "                    2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "                    3, 3, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1,\n",
       "                    1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
       "                    3, 3, 3, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 2, 2,\n",
       "                    2, 2, 2, 3, 3, 3, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 120, 130, 140, 150, 100, 120, 130, 140, 150, 100,\n",
       "                    120, 130, 140, 150, 100, 120, 130, 140, 150, 100, 120,\n",
       "                    130, 140, 150, 100, 120, 130, 140, 150, 100, 120, 130,\n",
       "                    140, 150, 100, 120, 130, 140, 150, 100, 120, 130, 140,\n",
       "                    150, 100, 120, 130, 140, 150, 100, 120, 130, 140, 150,\n",
       "                    100, 120, 130, 140, 150, 100, 120, 130, 140, 150, 100,\n",
       "                    120, 130, 140, 150, 100, 120, 130, 140, 150, 100, 120,\n",
       "                    130, 140, 150, 100, 120, 130, 140, 150, 100, 120, 130,\n",
       "                    140, 150, 100, 120, 130, 140, 150, 100, 120, 130, 140,\n",
       "                    150, 100, 120, 130, 140, 150, 100, 120, 130, 140, 150,\n",
       "                    100, 120, 130, 140, 150, 100, 120, 130, 140, 150, 100,\n",
       "                    120, 130, 140, 150, 100, 120, 130, 140, 150, 100, 120,\n",
       "                    130, 140, 150, 100, 120, 130, 140, 150, 100, 120, 130,\n",
       "                    140, 150, 100, 120, 130, 140, 150, 100, 120, 130, 140,\n",
       "                    150, 100, 120, 130, 140, 150, 100, 120, 130, 140, 150,\n",
       "                    100, 120, 130, 140, 150, 100, 120, 130, 140, 150, 100,\n",
       "                    120, 130, 140, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 0.5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 1,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 120},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 130},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 140},\n",
       "  {'criterion': 'log_loss',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.92307692, 0.92307692,\n",
       "        0.96153846, 0.92307692, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.92307692, 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.92307692, 0.92307692, 0.92307692,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.94871795, 0.93589744, 0.92307692, 0.93589744, 0.93589744,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.92307692, 0.92307692, 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.92307692, 0.91025641, 0.92307692,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92307692, 0.92307692, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.94871795, 0.94871795, 0.94871795, 0.93589744, 0.93589744,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.92307692, 0.92307692, 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.92307692, 0.91025641, 0.92307692,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92307692, 0.92307692, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.87179487, 0.88461538, 0.87179487, 0.87179487, 0.87179487,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.94871795, 0.94871795, 0.94871795, 0.93589744, 0.93589744]),\n",
       " 'split1_test_score': array([0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.84615385, 0.84615385, 0.84615385, 0.84615385, 0.84615385,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.87179487, 0.85897436,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.84615385,\n",
       "        0.84615385, 0.84615385, 0.84615385, 0.83333333, 0.84615385,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85897436, 0.87179487, 0.85897436, 0.84615385, 0.85897436,\n",
       "        0.87179487, 0.87179487, 0.87179487, 0.87179487, 0.87179487,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87179487, 0.85897436, 0.85897436, 0.87179487, 0.87179487,\n",
       "        0.84615385, 0.84615385, 0.84615385, 0.83333333, 0.84615385,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87179487, 0.88461538, 0.88461538, 0.87179487, 0.87179487,\n",
       "        0.84615385, 0.85897436, 0.87179487, 0.87179487, 0.85897436,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85897436, 0.87179487, 0.85897436, 0.85897436, 0.85897436,\n",
       "        0.84615385, 0.84615385, 0.84615385, 0.84615385, 0.85897436,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87179487, 0.85897436, 0.85897436, 0.87179487, 0.87179487,\n",
       "        0.84615385, 0.84615385, 0.84615385, 0.83333333, 0.84615385,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87179487, 0.88461538, 0.88461538, 0.87179487, 0.87179487,\n",
       "        0.84615385, 0.85897436, 0.87179487, 0.87179487, 0.85897436,\n",
       "        0.80769231, 0.79487179, 0.80769231, 0.80769231, 0.79487179,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85897436, 0.87179487, 0.85897436, 0.85897436, 0.85897436,\n",
       "        0.84615385, 0.84615385, 0.84615385, 0.84615385, 0.85897436]),\n",
       " 'split2_test_score': array([0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.91025641, 0.91025641, 0.92307692, 0.92307692, 0.92307692,\n",
       "        0.91025641, 0.91025641, 0.91025641, 0.91025641, 0.92307692,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.94871795, 0.93589744,\n",
       "        0.94871795, 0.94871795, 0.94871795, 0.94871795, 0.94871795,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92307692, 0.91025641, 0.93589744, 0.92307692, 0.92307692,\n",
       "        0.92307692, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92307692, 0.92307692, 0.93589744, 0.93589744, 0.94871795,\n",
       "        0.92307692, 0.92307692, 0.92307692, 0.93589744, 0.92307692,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.93589744, 0.92307692, 0.92307692, 0.94871795, 0.94871795,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92307692, 0.91025641, 0.93589744, 0.92307692, 0.92307692,\n",
       "        0.92307692, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92307692, 0.92307692, 0.93589744, 0.93589744, 0.94871795,\n",
       "        0.92307692, 0.92307692, 0.92307692, 0.93589744, 0.92307692,\n",
       "        0.85897436, 0.85897436, 0.85897436, 0.85897436, 0.85897436,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93589744, 0.93589744, 0.93589744, 0.93589744, 0.93589744,\n",
       "        0.93589744, 0.92307692, 0.92307692, 0.94871795, 0.94871795]),\n",
       " 'split3_test_score': array([0.79220779, 0.80519481, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.84415584, 0.84415584, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.87012987, 0.85714286,\n",
       "        0.79220779, 0.80519481, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.88311688,\n",
       "        0.85714286, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.79220779, 0.80519481, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.88311688, 0.90909091, 0.90909091, 0.8961039 ,\n",
       "        0.8961039 , 0.92207792, 0.92207792, 0.92207792, 0.92207792,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.8961039 , 0.8961039 , 0.88311688,\n",
       "        0.90909091, 0.90909091, 0.8961039 , 0.90909091, 0.90909091,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.85714286, 0.85714286, 0.88311688, 0.88311688,\n",
       "        0.92207792, 0.92207792, 0.90909091, 0.90909091, 0.92207792,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.8961039 , 0.8961039 , 0.88311688,\n",
       "        0.90909091, 0.90909091, 0.8961039 , 0.90909091, 0.90909091,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.85714286, 0.85714286, 0.88311688, 0.88311688,\n",
       "        0.92207792, 0.92207792, 0.90909091, 0.90909091, 0.92207792]),\n",
       " 'split4_test_score': array([0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.90909091, 0.8961039 ,\n",
       "        0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.8961039 , 0.90909091,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.93506494, 0.93506494, 0.93506494, 0.93506494, 0.93506494,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.83116883, 0.81818182, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.8961039 , 0.90909091,\n",
       "        0.92207792, 0.92207792, 0.92207792, 0.92207792, 0.92207792,\n",
       "        0.83116883, 0.81818182, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.90909091, 0.8961039 , 0.88311688, 0.88311688, 0.87012987,\n",
       "        0.83116883, 0.81818182, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92207792, 0.92207792, 0.92207792, 0.90909091, 0.92207792,\n",
       "        0.92207792, 0.8961039 , 0.8961039 , 0.92207792, 0.90909091,\n",
       "        0.83116883, 0.81818182, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.8961039 , 0.90909091,\n",
       "        0.92207792, 0.92207792, 0.92207792, 0.92207792, 0.92207792,\n",
       "        0.83116883, 0.81818182, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.90909091, 0.8961039 , 0.88311688, 0.88311688, 0.87012987,\n",
       "        0.83116883, 0.81818182, 0.83116883, 0.83116883, 0.83116883,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92207792, 0.92207792, 0.92207792, 0.90909091, 0.92207792,\n",
       "        0.92207792, 0.8961039 , 0.8961039 , 0.92207792, 0.90909091]),\n",
       " 'split5_test_score': array([0.75324675, 0.76623377, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.85714286, 0.83116883, 0.83116883, 0.83116883,\n",
       "        0.88311688, 0.87012987, 0.85714286, 0.83116883, 0.83116883,\n",
       "        0.75324675, 0.76623377, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.90909091,\n",
       "        0.90909091, 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.75324675, 0.76623377, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.90909091, 0.92207792,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.76623377, 0.80519481, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.84415584, 0.84415584, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.84415584, 0.84415584, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.76623377, 0.80519481, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.8961039 , 0.8961039 ,\n",
       "        0.76623377, 0.80519481, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.76623377, 0.80519481, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.84415584, 0.84415584, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.84415584, 0.84415584, 0.84415584, 0.84415584, 0.84415584,\n",
       "        0.76623377, 0.80519481, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.8961039 , 0.8961039 ,\n",
       "        0.76623377, 0.80519481, 0.76623377, 0.76623377, 0.76623377,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 , 0.8961039 ]),\n",
       " 'split6_test_score': array([0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.80519481, 0.80519481, 0.79220779, 0.79220779, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.80519481, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.85714286, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.87012987, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.85714286, 0.85714286, 0.84415584, 0.84415584, 0.85714286,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.85714286, 0.85714286, 0.87012987,\n",
       "        0.85714286, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.85714286, 0.85714286, 0.84415584, 0.84415584, 0.85714286,\n",
       "        0.79220779, 0.79220779, 0.79220779, 0.79220779, 0.79220779,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.85714286, 0.85714286, 0.87012987,\n",
       "        0.85714286, 0.87012987, 0.87012987, 0.87012987, 0.87012987]),\n",
       " 'split7_test_score': array([0.79220779, 0.80519481, 0.79220779, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.79220779, 0.80519481, 0.79220779, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.8961039 , 0.8961039 , 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.79220779, 0.80519481, 0.79220779, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.92207792, 0.92207792, 0.92207792, 0.90909091, 0.90909091,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.79220779, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.79220779, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.90909091, 0.90909091,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.88311688, 0.88311688,\n",
       "        0.79220779, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.92207792, 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.79220779, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.79220779, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.90909091, 0.90909091,\n",
       "        0.8961039 , 0.8961039 , 0.8961039 , 0.88311688, 0.88311688,\n",
       "        0.79220779, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,\n",
       "        0.92207792, 0.90909091, 0.90909091, 0.90909091, 0.90909091]),\n",
       " 'split8_test_score': array([0.72727273, 0.71428571, 0.72727273, 0.71428571, 0.7012987 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.81818182, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "        0.83116883, 0.83116883, 0.81818182, 0.81818182, 0.81818182,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.71428571, 0.7012987 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.88311688, 0.8961039 , 0.8961039 , 0.8961039 , 0.85714286,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.71428571, 0.7012987 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.72727273, 0.71428571,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.83116883,\n",
       "        0.84415584, 0.84415584, 0.83116883, 0.84415584, 0.84415584,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.72727273, 0.71428571,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.87012987, 0.87012987,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.72727273, 0.71428571,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.87012987, 0.88311688, 0.87012987, 0.88311688, 0.88311688,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.72727273, 0.71428571,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.83116883,\n",
       "        0.84415584, 0.84415584, 0.83116883, 0.84415584, 0.84415584,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.72727273, 0.71428571,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.87012987, 0.87012987,\n",
       "        0.72727273, 0.71428571, 0.72727273, 0.72727273, 0.71428571,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.87012987, 0.88311688, 0.87012987, 0.88311688, 0.88311688]),\n",
       " 'split9_test_score': array([0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.83116883, 0.83116883, 0.84415584, 0.84415584,\n",
       "        0.85714286, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.87012987, 0.88311688, 0.87012987, 0.88311688, 0.88311688,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90909091, 0.8961039 , 0.90909091, 0.90909091, 0.8961039 ,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.8961039 ,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.84415584,\n",
       "        0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.84415584,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.85714286, 0.84415584,\n",
       "        0.83116883, 0.83116883, 0.83116883, 0.83116883, 0.84415584,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.87012987, 0.87012987, 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.87012987, 0.87012987, 0.87012987, 0.87012987, 0.87012987,\n",
       "        0.80519481, 0.80519481, 0.80519481, 0.80519481, 0.80519481,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688,\n",
       "        0.88311688, 0.88311688, 0.88311688, 0.88311688, 0.88311688]),\n",
       " 'mean_test_score': array([0.8031968 , 0.80579421, 0.8044955 , 0.8044955 , 0.80191475,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.86533467, 0.86143856, 0.86012321, 0.86013986, 0.86013986,\n",
       "        0.87307692, 0.87052947, 0.86921412, 0.87049617, 0.86660007,\n",
       "        0.8031968 , 0.80579421, 0.8044955 , 0.8044955 , 0.80191475,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.89518815, 0.89388944, 0.89388944, 0.89130869, 0.89388944,\n",
       "        0.88869464, 0.89129204, 0.89129204, 0.89130869, 0.88869464,\n",
       "        0.8031968 , 0.80579421, 0.8044955 , 0.8044955 , 0.80191475,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.90164835, 0.9042291 , 0.90684316, 0.90554446, 0.90424575,\n",
       "        0.9002997 , 0.90161505, 0.900333  , 0.90161505, 0.90291375,\n",
       "        0.8044955 , 0.80709291, 0.80579421, 0.80579421, 0.80321345,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.86918082, 0.86661672, 0.86789877, 0.86660007, 0.86530137,\n",
       "        0.86403596, 0.86531802, 0.86272061, 0.86145521, 0.86531802,\n",
       "        0.8044955 , 0.80709291, 0.80579421, 0.80579421, 0.80321345,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8951715 , 0.89515485, 0.89382284, 0.89383949, 0.89382284,\n",
       "        0.89259074, 0.89387279, 0.89125874, 0.88994339, 0.88737929,\n",
       "        0.8044955 , 0.80709291, 0.80579421, 0.80579421, 0.80321345,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.89515485, 0.8964369 , 0.89385614, 0.89515485, 0.89775225,\n",
       "        0.90034965, 0.8977689 , 0.8951715 , 0.90034965, 0.9016317 ,\n",
       "        0.8044955 , 0.80709291, 0.80579421, 0.80579421, 0.80321345,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.86918082, 0.86661672, 0.86789877, 0.86660007, 0.86530137,\n",
       "        0.86403596, 0.86531802, 0.86272061, 0.86145521, 0.86531802,\n",
       "        0.8044955 , 0.80709291, 0.80579421, 0.80579421, 0.80321345,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.8951715 , 0.89515485, 0.89382284, 0.89383949, 0.89382284,\n",
       "        0.89259074, 0.89387279, 0.89125874, 0.88994339, 0.88737929,\n",
       "        0.8044955 , 0.80709291, 0.80579421, 0.80579421, 0.80321345,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.89515485, 0.8964369 , 0.89385614, 0.89515485, 0.89775225,\n",
       "        0.90034965, 0.8977689 , 0.8951715 , 0.90034965, 0.9016317 ]),\n",
       " 'std_test_score': array([0.04152736, 0.04464144, 0.04012432, 0.04257177, 0.04544351,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.03879545, 0.04170454, 0.04731585, 0.04475034, 0.04475034,\n",
       "        0.04352284, 0.03739182, 0.04104384, 0.0400708 , 0.04292901,\n",
       "        0.04152736, 0.04464144, 0.04012432, 0.04257177, 0.04544351,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.02906563, 0.03041508, 0.02985539, 0.0277631 , 0.02636219,\n",
       "        0.0273161 , 0.02665422, 0.02789108, 0.02952943, 0.02910957,\n",
       "        0.04152736, 0.04464144, 0.04012432, 0.04257177, 0.04544351,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.02965153, 0.02543824, 0.02633296, 0.02998576, 0.02662206,\n",
       "        0.02794038, 0.02677481, 0.02537281, 0.02677481, 0.02615383,\n",
       "        0.04012432, 0.04247453, 0.03991521, 0.03991521, 0.04264917,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.04152382, 0.04007029, 0.04162113, 0.03842056, 0.04021294,\n",
       "        0.04217264, 0.04409888, 0.04525371, 0.04360966, 0.04371474,\n",
       "        0.04012432, 0.04247453, 0.03991521, 0.03991521, 0.04264917,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.0197297 , 0.01806846, 0.02472705, 0.02596658, 0.02845215,\n",
       "        0.02716847, 0.02517637, 0.02558609, 0.02816443, 0.02609161,\n",
       "        0.04012432, 0.04247453, 0.03991521, 0.03991521, 0.04264917,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.02751831, 0.02793702, 0.03063714, 0.02751831, 0.02686463,\n",
       "        0.03324415, 0.02796132, 0.02799533, 0.02947958, 0.0272924 ,\n",
       "        0.04012432, 0.04247453, 0.03991521, 0.03991521, 0.04264917,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.04152382, 0.04007029, 0.04162113, 0.03842056, 0.04021294,\n",
       "        0.04217264, 0.04409888, 0.04525371, 0.04360966, 0.04371474,\n",
       "        0.04012432, 0.04247453, 0.03991521, 0.03991521, 0.04264917,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.0197297 , 0.01806846, 0.02472705, 0.02596658, 0.02845215,\n",
       "        0.02716847, 0.02517637, 0.02558609, 0.02816443, 0.02609161,\n",
       "        0.04012432, 0.04247453, 0.03991521, 0.03991521, 0.04264917,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.02751831, 0.02793702, 0.03063714, 0.02751831, 0.02686463,\n",
       "        0.03324415, 0.02796132, 0.02799533, 0.02947958, 0.0272924 ]),\n",
       " 'rank_test_score': array([130,  97, 112, 112, 133, 136, 136, 136, 136, 136,  74,  87,  90,\n",
       "         88,  88,  61,  62,  64,  63,  71, 130,  97, 112, 112, 133, 136,\n",
       "        136, 136, 136, 136,  23,  34,  34,  49,  34,  57,  51,  52,  49,\n",
       "         57, 130,  97, 112, 112, 133, 136, 136, 136, 136, 136,   6,   4,\n",
       "          1,   2,   3,  16,   9,  15,   9,   5, 112,  91,  97,  97, 124,\n",
       "        136, 136, 136, 136, 136,  65,  69,  67,  71,  79,  81,  75,  83,\n",
       "         85,  75, 112,  91,  97,  97, 124, 136, 136, 136, 136, 136,  24,\n",
       "         28,  43,  41,  43,  47,  37,  53,  55,  59, 112,  91,  97,  97,\n",
       "        124, 136, 136, 136, 136, 136,  28,  21,  39,  28,  19,  11,  17,\n",
       "         24,  11,   7, 112,  91,  97,  97, 124, 136, 136, 136, 136, 136,\n",
       "         65,  69,  67,  71,  79,  81,  75,  83,  85,  75, 112,  91,  97,\n",
       "         97, 124, 136, 136, 136, 136, 136,  24,  28,  43,  41,  43,  47,\n",
       "         37,  53,  55,  59, 112,  91,  97,  97, 124, 136, 136, 136, 136,\n",
       "        136,  28,  21,  39,  28,  19,  11,  17,  24,  11,   7])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[100,120,130,140,150],\n",
    "    'max_depth':[6,8,10],\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'min_samples_split' : [0.5,1,2,3]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42,max_leaf_nodes=127),param_grid=params,cv=10)\n",
    "\n",
    "clf.fit(X_train,train_targets)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082571</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.803197</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104560</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>120</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.805794</td>\n",
       "      <td>0.044641</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110260</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>130</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.804496</td>\n",
       "      <td>0.040124</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117694</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.007648</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>140</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.804496</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127083</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 6, 'min_sam...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.801915</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.082571      0.007559         0.005537        0.000551   \n",
       "1       0.104560      0.006763         0.006942        0.000890   \n",
       "2       0.110260      0.008468         0.006959        0.000473   \n",
       "3       0.117694      0.003800         0.007648        0.000793   \n",
       "4       0.127083      0.006983         0.008308        0.000402   \n",
       "\n",
       "  param_criterion param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "0            gini               6                     0.5                100   \n",
       "1            gini               6                     0.5                120   \n",
       "2            gini               6                     0.5                130   \n",
       "3            gini               6                     0.5                140   \n",
       "4            gini               6                     0.5                150   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'criterion': 'gini', 'max_depth': 6, 'min_sam...           0.871795  ...   \n",
       "1  {'criterion': 'gini', 'max_depth': 6, 'min_sam...           0.884615  ...   \n",
       "2  {'criterion': 'gini', 'max_depth': 6, 'min_sam...           0.871795  ...   \n",
       "3  {'criterion': 'gini', 'max_depth': 6, 'min_sam...           0.871795  ...   \n",
       "4  {'criterion': 'gini', 'max_depth': 6, 'min_sam...           0.871795  ...   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0           0.792208           0.831169           0.753247           0.792208   \n",
       "1           0.805195           0.831169           0.766234           0.792208   \n",
       "2           0.792208           0.831169           0.766234           0.792208   \n",
       "3           0.792208           0.831169           0.766234           0.792208   \n",
       "4           0.792208           0.831169           0.766234           0.792208   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0           0.792208           0.727273           0.805195         0.803197   \n",
       "1           0.805195           0.714286           0.805195         0.805794   \n",
       "2           0.792208           0.727273           0.805195         0.804496   \n",
       "3           0.805195           0.714286           0.805195         0.804496   \n",
       "4           0.805195           0.701299           0.805195         0.801915   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.041527              130  \n",
       "1        0.044641               97  \n",
       "2        0.040124              112  \n",
       "3        0.042572              112  \n",
       "4        0.045444              133  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df = pd.DataFrame(clf.cv_results_)\n",
    "rf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 130}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9068431568431568"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.803197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.805794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.804496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.804496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.801915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>0.900350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>0.897769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>0.895171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>0.900350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>log_loss</td>\n",
       "      <td>10</td>\n",
       "      <td>0.901632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_criterion param_max_depth  mean_test_score\n",
       "0              gini               6         0.803197\n",
       "1              gini               6         0.805794\n",
       "2              gini               6         0.804496\n",
       "3              gini               6         0.804496\n",
       "4              gini               6         0.801915\n",
       "..              ...             ...              ...\n",
       "175        log_loss              10         0.900350\n",
       "176        log_loss              10         0.897769\n",
       "177        log_loss              10         0.895171\n",
       "178        log_loss              10         0.900350\n",
       "179        log_loss              10         0.901632\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df[['param_criterion','param_max_depth','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = {\n",
    "    'random_state':42,\n",
    "    'n_estimators':130,\n",
    "    'max_depth':10,\n",
    "    'max_leaf_nodes':127,\n",
    "    'n_jobs':-1, \n",
    "    'random_state':42,\n",
    "    'max_samples':0.97, \n",
    "    'criterion':'gini',\n",
    "    'min_weight_fraction_leaf' :0.000976,\n",
    "    'max_samples' : 0.99999898898772828,\n",
    "    'max_features' : 'log2',\n",
    "    'ccp_alpha' : 0.0000099765626787\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score - 99.35%\n",
      "val_score - 93.53%\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(**best_params_rf).fit(X_train,train_targets)\n",
    "print(f'train_score - {round(best_model.score(X_train,train_targets)*100,2)}%')\n",
    "print(f'val_score - {round(best_model.score(X_val,val_targets)*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RandomizedSearchCV to reduce number of iterations and with random combination of parameters. This is useful when you have too many parameters to try and your training time is longer. It helps reduce the cost of computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.86663337        nan 0.86918082        nan 0.8044955  0.80579421\n",
      " 0.86663337 0.88611389 0.86921412        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.16590002, 0.0002104 , 0.18220131, 0.00050392, 0.09798617,\n",
       "        0.09772806, 0.15350294, 0.20905604, 0.15768387, 0.00050237]),\n",
       " 'std_fit_time': array([0.00830037, 0.00037903, 0.00494974, 0.00050419, 0.00281134,\n",
       "        0.00812438, 0.00204485, 0.00915232, 0.03662216, 0.00045451]),\n",
       " 'mean_score_time': array([0.00752034, 0.        , 0.00761476, 0.        , 0.00679829,\n",
       "        0.00671008, 0.00630493, 0.00737219, 0.00677657, 0.        ]),\n",
       " 'std_score_time': array([0.00120439, 0.        , 0.00084391, 0.        , 0.00071572,\n",
       "        0.00106649, 0.0007036 , 0.00064391, 0.00204424, 0.        ]),\n",
       " 'param_n_estimators': masked_array(data=[130, 100, 150, 140, 140, 130, 130, 150, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[3, 1, 2, 1, 0.5, 0.5, 3, 2, 2, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[6, 6, 6, 8, 8, 10, 6, 8, 6, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['entropy', 'gini', 'log_loss', 'log_loss', 'gini',\n",
       "                    'log_loss', 'log_loss', 'entropy', 'entropy',\n",
       "                    'log_loss'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 130,\n",
       "   'min_samples_split': 3,\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 1,\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 150,\n",
       "   'min_samples_split': 2,\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 140,\n",
       "   'min_samples_split': 1,\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 140,\n",
       "   'min_samples_split': 0.5,\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'gini'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 0.5,\n",
       "   'max_depth': 10,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 130,\n",
       "   'min_samples_split': 3,\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'log_loss'},\n",
       "  {'n_estimators': 150,\n",
       "   'min_samples_split': 2,\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 2,\n",
       "   'max_depth': 6,\n",
       "   'criterion': 'entropy'},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 1,\n",
       "   'max_depth': 8,\n",
       "   'criterion': 'log_loss'}],\n",
       " 'split0_test_score': array([0.92307692,        nan, 0.94871795,        nan, 0.87179487,\n",
       "        0.87179487, 0.92307692, 0.92307692, 0.92307692,        nan]),\n",
       " 'split1_test_score': array([0.84615385,        nan, 0.85897436,        nan, 0.80769231,\n",
       "        0.80769231, 0.84615385, 0.84615385, 0.84615385,        nan]),\n",
       " 'split2_test_score': array([0.92307692,        nan, 0.92307692,        nan, 0.85897436,\n",
       "        0.85897436, 0.92307692, 0.92307692, 0.93589744,        nan]),\n",
       " 'split3_test_score': array([0.88311688,        nan, 0.88311688,        nan, 0.79220779,\n",
       "        0.79220779, 0.88311688, 0.84415584, 0.84415584,        nan]),\n",
       " 'split4_test_score': array([0.8961039 ,        nan, 0.8961039 ,        nan, 0.83116883,\n",
       "        0.83116883, 0.8961039 , 0.88311688, 0.8961039 ,        nan]),\n",
       " 'split5_test_score': array([0.85714286,        nan, 0.83116883,        nan, 0.76623377,\n",
       "        0.76623377, 0.85714286, 0.90909091, 0.85714286,        nan]),\n",
       " 'split6_test_score': array([0.79220779,        nan, 0.79220779,        nan, 0.79220779,\n",
       "        0.79220779, 0.79220779, 0.87012987, 0.83116883,        nan]),\n",
       " 'split7_test_score': array([0.87012987,        nan, 0.87012987,        nan, 0.80519481,\n",
       "        0.80519481, 0.87012987, 0.88311688, 0.88311688,        nan]),\n",
       " 'split8_test_score': array([0.83116883,        nan, 0.84415584,        nan, 0.71428571,\n",
       "        0.72727273, 0.83116883, 0.88311688, 0.84415584,        nan]),\n",
       " 'split9_test_score': array([0.84415584,        nan, 0.84415584,        nan, 0.80519481,\n",
       "        0.80519481, 0.84415584, 0.8961039 , 0.83116883,        nan]),\n",
       " 'mean_test_score': array([0.86663337,        nan, 0.86918082,        nan, 0.8044955 ,\n",
       "        0.80579421, 0.86663337, 0.88611389, 0.86921412,        nan]),\n",
       " 'std_test_score': array([0.03916097,        nan, 0.04344806,        nan, 0.04257177,\n",
       "        0.03991521, 0.03916097, 0.0264575 , 0.03618346,        nan]),\n",
       " 'rank_test_score': array([4, 8, 3, 8, 7, 6, 4, 1, 2, 8])}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,120,130,140,150],\n",
    "    'max_depth':[6,8,10],\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'min_samples_split' : [0.5,1,2,3]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(random_state=42,max_leaf_nodes=127),\n",
    "            {'n_estimators':[100,120,130,140,150],\n",
    "    'max_depth':[6,8,10],\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'min_samples_split' : [0.5,1,2,3]\n",
    "                             \n",
    "                         },\n",
    "                         \n",
    "cv=10)\n",
    "\n",
    "clf.fit(X_train,train_targets)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'n_estimators': 130, 'min_samples_split': 3, ...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.866633</td>\n",
       "      <td>0.039161</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.182201</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 150, 'min_samples_split': 2, ...</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.869181</td>\n",
       "      <td>0.043448</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>{'n_estimators': 140, 'min_samples_split': 1, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097986</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>140</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'n_estimators': 140, 'min_samples_split': 0.5...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.804496</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.165900      0.008300         0.007520        0.001204   \n",
       "1       0.000210      0.000379         0.000000        0.000000   \n",
       "2       0.182201      0.004950         0.007615        0.000844   \n",
       "3       0.000504      0.000504         0.000000        0.000000   \n",
       "4       0.097986      0.002811         0.006798        0.000716   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_max_depth param_criterion  \\\n",
       "0                130                       3               6         entropy   \n",
       "1                100                       1               6            gini   \n",
       "2                150                       2               6        log_loss   \n",
       "3                140                       1               8        log_loss   \n",
       "4                140                     0.5               8            gini   \n",
       "\n",
       "                                              params  split0_test_score  ...  \\\n",
       "0  {'n_estimators': 130, 'min_samples_split': 3, ...           0.923077  ...   \n",
       "1  {'n_estimators': 100, 'min_samples_split': 1, ...                NaN  ...   \n",
       "2  {'n_estimators': 150, 'min_samples_split': 2, ...           0.948718  ...   \n",
       "3  {'n_estimators': 140, 'min_samples_split': 1, ...                NaN  ...   \n",
       "4  {'n_estimators': 140, 'min_samples_split': 0.5...           0.871795  ...   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0           0.883117           0.896104           0.857143           0.792208   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2           0.883117           0.896104           0.831169           0.792208   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           0.792208           0.831169           0.766234           0.792208   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0           0.870130           0.831169           0.844156         0.866633   \n",
       "1                NaN                NaN                NaN              NaN   \n",
       "2           0.870130           0.844156           0.844156         0.869181   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4           0.805195           0.714286           0.805195         0.804496   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.039161                4  \n",
       "1             NaN                8  \n",
       "2        0.043448                3  \n",
       "3             NaN                8  \n",
       "4        0.042572                7  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df = pd.DataFrame(clf.cv_results_)\n",
    "rf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150,\n",
       " 'min_samples_split': 2,\n",
       " 'max_depth': 8,\n",
       " 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886113886113886"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_params = {\n",
    "    'decision_tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params' : {\n",
    "            'max_features' : [\"sqrt\", \"log2\"],\n",
    "            'max_depth': [2,4,6,8,10,12],\n",
    "            'criterion':['gini','entropy','log_loss'],\n",
    "\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(random_state=42 , max_leaf_nodes=127),\n",
    "        'params' : {\n",
    "            'n_estimators':[100,120,130,140,150],\n",
    "    'max_depth':[6,8,10],\n",
    "    'criterion':['gini','entropy','log_loss'],\n",
    "    'min_samples_split' : [0.5,1,2,3]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "675 fits failed out of a total of 2700.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "675 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Saket\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.80962795 0.81091001 0.80703871 0.80837104 0.8083459         nan\n",
      "        nan        nan        nan        nan 0.86661639 0.86141277\n",
      " 0.86269482 0.86013072 0.86010558 0.86792358 0.8653092  0.86013072\n",
      " 0.85887381 0.86143791 0.80962795 0.81091001 0.80703871 0.80837104\n",
      " 0.8083459         nan        nan        nan        nan        nan\n",
      " 0.89115133 0.89896933 0.90025138 0.89896933 0.90155857 0.89115133\n",
      " 0.88986928 0.88986928 0.89376571 0.89120161 0.80962795 0.81091001\n",
      " 0.80703871 0.80837104 0.8083459         nan        nan        nan\n",
      "        nan        nan 0.89761187 0.90661136 0.90276521 0.90020111\n",
      " 0.90020111 0.89891905 0.90409754 0.90279035 0.89376571 0.8950729\n",
      " 0.80832076 0.81347411 0.80575666 0.80837104 0.8083459         nan\n",
      "        nan        nan        nan        nan 0.86918049 0.86918049\n",
      " 0.86659125 0.86528406 0.86271996 0.86659125 0.8653092  0.86269482\n",
      " 0.86400201 0.86269482 0.80832076 0.81347411 0.80575666 0.80837104\n",
      " 0.8083459         nan        nan        nan        nan        nan\n",
      " 0.89371543 0.89115133 0.88861237 0.88989442 0.88986928 0.89112619\n",
      " 0.8872549  0.8872549  0.88728004 0.88856209 0.80832076 0.81347411\n",
      " 0.80575666 0.80837104 0.8083459         nan        nan        nan\n",
      "        nan        nan 0.89761187 0.90017597 0.89504776 0.90274007\n",
      " 0.90017597 0.90276521 0.90404726 0.9015083  0.9040724  0.9040724\n",
      " 0.80832076 0.81347411 0.80575666 0.80837104 0.8083459         nan\n",
      "        nan        nan        nan        nan 0.86918049 0.86918049\n",
      " 0.86659125 0.86528406 0.86271996 0.86659125 0.8653092  0.86269482\n",
      " 0.86400201 0.86269482 0.80832076 0.81347411 0.80575666 0.80837104\n",
      " 0.8083459         nan        nan        nan        nan        nan\n",
      " 0.89371543 0.89115133 0.88861237 0.88989442 0.88986928 0.89112619\n",
      " 0.8872549  0.8872549  0.88728004 0.88856209 0.80832076 0.81347411\n",
      " 0.80575666 0.80837104 0.8083459         nan        nan        nan\n",
      "        nan        nan 0.89761187 0.90017597 0.89504776 0.90274007\n",
      " 0.90017597 0.90276521 0.90404726 0.9015083  0.9040724  0.9040724 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.857516</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 12, 'max_fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.906611</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.817396</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0        decision_tree    0.857516   \n",
       "1        random_forest    0.906611   \n",
       "2  logistic_regression    0.817396   \n",
       "\n",
       "                                         best_params  \n",
       "0  {'criterion': 'gini', 'max_depth': 12, 'max_fe...  \n",
       "1  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  \n",
       "2                                           {'C': 5}  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=15, return_train_score=False)\n",
    "    clf.fit(X_train,train_targets)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 120}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['best_params'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score - 99.48%\n",
      "val_score - 93.53%\n"
     ]
    }
   ],
   "source": [
    "best_params_rf = {\n",
    "    'random_state':42,\n",
    "    'n_estimators':120,\n",
    "    'max_depth':10,\n",
    "    'max_leaf_nodes':127,\n",
    "    'n_jobs':-1, \n",
    "    'random_state':42,\n",
    "    'max_samples':0.97, \n",
    "    'criterion':'gini',\n",
    "    'min_weight_fraction_leaf' :0.000976,\n",
    "    'max_samples' : 0.99999898898772828,\n",
    "    'max_features' : 'log2',\n",
    "    'ccp_alpha' : 0.0000099765626787\n",
    "}\n",
    "\n",
    "best_model = RandomForestClassifier(**best_params_rf).fit(X_train,train_targets)\n",
    "print(f'train_score - {round(best_model.score(X_train,train_targets)*100,2)}%')\n",
    "print(f'val_score - {round(best_model.score(X_val,val_targets)*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
